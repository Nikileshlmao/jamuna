{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9f0b37-fbfe-4e59-ab32-da1c1afe3b00",
   "metadata": {},
   "source": [
    "## RAG using a pdf book\n",
    "* see: https://python.langchain.com/docs/use_cases/question_answering/\n",
    "* using **Cohere** embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75812374-a9a1-4463-93a2-6dd6f352cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pdf post processing\n",
    "import re\n",
    "\n",
    "# modified to load from Pdf\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# two possible vector store\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# removed OpenAI, using Cohere embeddings\n",
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "# removed OpenAI, using OCI GenAI\n",
    "from oci.config import from_file\n",
    "\n",
    "# oci_llm is in a local file\n",
    "from oci_llm import OCIGenAILLM\n",
    "\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# private configs\n",
    "from config_private import COMPARTMENT_OCID, COHERE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaede75f-e609-4cc6-a077-259b3a439bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to enable some debugging\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79547220-85f9-4e02-9dbb-0a76717d684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def get_answer(rag_chain, question):\n",
    "    response = rag_chain.invoke(question)\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"The response:\")\n",
    "    print(response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef483ade-2146-4218-8130-95abe1607a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read OCI config to connect to OCI with API key\n",
    "CONFIG_PROFILE = \"DEFAULT\"\n",
    "config = from_file(\"~/.oci/config\", CONFIG_PROFILE)\n",
    "\n",
    "# OCI GenAI endpoint (for now Chicago)\n",
    "ENDPOINT = \"https://generativeai.aiservice.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "# check the config to access to api keys\n",
    "if DEBUG:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b988c589-f06e-49f7-b23f-f70ab316e720",
   "metadata": {},
   "source": [
    "#### Loading the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5edf3f-17df-4963-82ef-d4297239dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLOG_POST = \"https://python.langchain.com/docs/get_started/introduction\"\n",
    "BOOK = \"./oracle-database-23c-new-features-guide.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(BOOK)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd8887b-0aff-45b8-9df2-ea904815ea26",
   "metadata": {},
   "source": [
    "#### Splitting the document in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f53344e-271e-4484-bd29-c95a02b35d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with smaller chuncks\n",
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 50\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89b1b9f1-d375-4a68-b25a-633930c2462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have splitted the pdf in 436 splits...\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have splitted the pdf in {len(splits)} splits...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b35bb4e-44d8-4c48-bceb-c10873c93c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some post processing\n",
    "\n",
    "for split in splits:\n",
    "    split.page_content = split.page_content.replace(\"\\n\", \" \")\n",
    "    split.page_content = re.sub(\"[^a-zA-Z0-9 \\n\\.]\", \" \", split.page_content)\n",
    "    # remove duplicate blank\n",
    "    split.page_content = \" \".join(split.page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f70cce26-c603-4532-8ab6-8c34fa4d857e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oracle Call Interface OCI Session Pool Statistics 2 24 Oracle Connection Manager in Traffic Director Mode CMAN TDM Support for Direct Path Applications 2 24 Oracle Connection Manager in Traffic Director Mode CMAN TDM Usage Statistics 2 24 Resumable Cursors 2 25 Shut Down Connection Draining for Database Resident Connection Pooling DRCP 2 25 UCP Support for XA Transactions with Sharded Databases 2 25 Database Drivers API Enhancements 2 26 JDBC Support for Database Annotation 2 26'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a look at a single split\n",
    "splits[20].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4830653-e501-4dda-a26e-8faef61a0531",
   "metadata": {},
   "source": [
    "#### Embeddings and Vectore Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a63cc21-2225-4e1f-8b3a-6ec41ca97d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 255 ms, total: 1.94 s\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# We have substituted OpenAI with HF# see leaderboard here: https://huggingface.co/spaces/mteb/leaderboard\n",
    "# EMBED_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "cohere = CohereEmbeddings(cohere_api_key=COHERE_API_KEY)\n",
    "\n",
    "# using Chroma or FAISS as Vector store\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=cohere)\n",
    "# vectorstore = FAISS.from_documents(documents=splits, embedding=hf)\n",
    "\n",
    "# increased num. of docs to 10 (default to 4)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aaa4a5-ba64-4222-a65c-d26e5395cd3f",
   "metadata": {},
   "source": [
    "#### Define the prompt structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "426d2dd3-ac41-4cb2-a975-b35ca482fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be2ef0b-f63b-4138-8bd9-5271e66ee926",
   "metadata": {},
   "source": [
    "#### Define the LLM: OCI GenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d5f0d42-8203-4950-a5ca-8c051ff71b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compartment OCID from config_private.py\n",
    "\n",
    "llm = OCIGenAILLM(\n",
    "    temperature=1,\n",
    "    max_tokens=1500,\n",
    "    config=config,\n",
    "    compartment_id=COMPARTMENT_OCID,\n",
    "    endpoint=ENDPOINT,\n",
    "    debug=DEBUG,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe0dca-b88e-4c5f-9b03-25da1ed36cb2",
   "metadata": {},
   "source": [
    "#### Define the (Lang)Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e93a1de-9939-4120-8910-66d735de7beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | rag_prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce71ae-50a8-418d-81ea-cea0a30d11cf",
   "metadata": {},
   "source": [
    "#### Process the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5562c9d-cc2a-4761-9625-1c62a45cf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of possible questions\n",
    "QUESTION1 = \"What is the best architecture for an LLM?\"\n",
    "QUESTION2 = \"What is LangChain?\"\n",
    "QUESTION3 = \"Make a list of database 23c innovations in AI\"\n",
    "QUESTION4 = \"List the new features in Oracle Database 23c\"\n",
    "QUESTION5 = \"Describe JSON relational duality\"\n",
    "QUESTION6 = \"Are there features related to Machine Learning in Oracle Database 23c?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "069689c8-4786-455b-aee0-91f1fc69e0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: List the new features in Oracle Database 23c\n",
      "The response:\n",
      " Some of the new features in Oracle Database 23c include:\n",
      "- Up to 4096 columns per table\n",
      "- Improved machine learning algorithms\n",
      "- Simplified database migration across platforms using RMAN\n",
      "- Support for Oracle Database Version Specific RMAN SBT Library\n",
      "- Blockchain Table User Chains\n",
      "- Blockchain Table Row Versions\n",
      "- Resumable Cursors\n",
      "- Shut Down Connection Draining for Database Resident Connection Pooling DRCP\n",
      "- UCP Support for XA Transactions with Sharded Databases\n",
      "- Database Drivers API Enhancements\n",
      "- JDBC Support for Database Annotation\n",
      "- CMAN TDM Support for Direct Path Applications\n",
      "- Oracle Connection Manager in Traffic Director Mode CMAN TDM Usage Statistics\n",
      "- Selective In Memory Columns\n",
      "- In Memory Advisor\n",
      "- OCI and OCCI Password Length Increase\n",
      "- Updated Kerberos Library and Other Improvements\n",
      "- Enhancements to RADIUS Configuration\n",
      "- UTL HTTP Support for SHA 256 and Other Digest Authentication Standards\n",
      "- XDB HTTP SHA512 Digest Authentication\n",
      "- General Security SQL Firewall\n",
      "- Oracle SQL Firewall Included in Oracle Database\n",
      "- Encryption\n",
      "- Transport Layer Security TLS 1.3 Now Supported in Oracle Database\n",
      "- Redo Decryption for Hybrid Disaster Recovery Configurations\n",
      "- Flashback Time Travel Enhancements\n",
      "- Minimized Stall and More Accurate Lag Detection in Fast Start Failover\n",
      "- Transaction Guard Support during DBMS ROLLING BACK\n",
      "- PL SQL Function Cross Shard Query Support\n",
      "- Pre Deployment Diagnostic for Oracle Globally Distributed Database\n",
      "- RMAN Backup Encryption Algorithm Now Defaults to AES256\n",
      "- RMAN Operational Diagnostics and Upgrade Enhancements\n",
      "- Automatic SecureFiles Shrink for Autonomous Database\n",
      "- Automatic Storage Compression\n",
      "- Enhanced Query History Tracking and Reporting\n",
      "- Improved Performance of LOB Writes\n",
      "- New improvements to Oracle In Database Machine Learning algorithms make it simpler to categorize text and data while offering better performance and flexibility\n",
      "- Simplified development of applications needing large numbers of attributes such as ML and IoT\n",
      "- High Availability Data Guard\n",
      "- Oracle Data Guard Redo Decryption for Hybrid Disaster Recovery Configurations\n",
      "- Flashback Time Travel Enhancements\n",
      "- Minimized Stall and More Accurate Lag Detection in Fast Start Failover\n",
      "- Maximum Performance\n",
      "- Security\n",
      "- SQL Firewall\n",
      "- Oracle SQL Firewall Included in Oracle Database\n",
      "- Encryption\n",
      "- Transport Layer Security TLS 1.3 Now Supported in Oracle Database\n",
      "- Parallel Cross Shard DML Support\n",
      "- PL SQL Function Cross Shard Query Support\n",
      "- Pre Deployment Diagnostic for Oracle Globally Distributed Database\n",
      "- RMAN Backup Encryption Algorithm Now Defaults to AES256\n",
      "- RMAN Operational Diagnostics and Upgrade Enhancements\n",
      "- Simplified Database Migration Across Platforms Using RMAN\n",
      "- Support for Oracle Database Version Specific RMAN SBT Library\n",
      "- Blockchain\n",
      "- Blockchain Table User Chains\n",
      "- Blockchain Table Row Versions\n",
      "\n",
      "I could not find further information on new features in Oracle Database 23c.\n",
      "\n",
      "CPU times: user 69.9 ms, sys: 9.88 ms, total: 79.8 ms\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# the question\n",
    "get_answer(rag_chain, question=QUESTION4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c8d730d-dd1b-4ee7-b2f0-1bdd60a9cf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Describe JSON relational duality\n",
      "The response:\n",
      " JSON relational duality is a feature where you can access and update data as either JSON documents or relational tables. This allows developers to take advantage of the strengths of both models, which are simpler and more powerful than Object Relational Mapping (ORM). \n",
      "\n",
      "This concept can be explained further by looking at an example. Let's say you have a database that stores customer information in a relational format. You can use JSON relational duality to access this data in a JSON format, which is easier to work with for many developers.\n",
      "\n",
      "The benefits of using JSON relational duality include:\n",
      "\n",
      "- Simplifying development: By using a single API to work with both relational and JSON data, you can reduce the complexity of your code and make it more maintainable.\n",
      "- Enhancing performance: By allowing you to access and update data in a more efficient format, you can improve the performance of your applications.\n",
      "- Reducing data duplication: By using a single data store for both relational and JSON data, you can avoid having to maintain separate data sets and reduce data duplication.\n",
      "\n",
      "In addition to these benefits, JSON relational duality can also help you to:\n",
      "\n",
      "- Ensure data consistency: By using a single data store, you can ensure that your data is always consistent and up-to-date.\n",
      "- Simplify data management: By using a single data store, you can simplify data management and reduce the complexity of your data infrastructure.\n",
      "- Reduce the risk of data loss: By using a single data store, you can reduce the risk of data loss and ensure that your data is always backed up and accessible.\n",
      "\n",
      "Overall, JSON relational duality is a powerful feature that can simplify development, enhance performance, and reduce data duplication. By allowing developers to work with data in both relational and JSON formats, it can help to streamline the development process and improve the overall performance of your applications.\n",
      "\n",
      "CPU times: user 48.1 ms, sys: 8.89 ms, total: 57 ms\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# the question\n",
    "get_answer(rag_chain, question=QUESTION5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98885a05-0118-4514-90ac-f1912dbe5187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Are there features related to Machine Learning in Oracle Database 23c?\n",
      "The response:\n",
      " Yes, there are features related to Machine Learning in Oracle Database 23c. Some of these features include:\n",
      "- Improved Machine Learning Algorithms: New improvements to Oracle In Database Machine Learning algorithms make it simpler to categorize text and data while offering better performance and flexibility.\n",
      "- Automated Time Series Model Search: This feature enables the Exponential Smoothing algorithm to select the forecasting model type automatically as well as related hyperparameters when you do not.\n",
      "- Parallel Cross Shard DML Support: This feature allows you to run DML statements in parallel across multiple shards of a table.\n",
      "- PL SQL Function Cross Shard Query Support: This feature enables you to execute a query in parallel across multiple shards of a table.\n",
      "- In Memory RAC Level Global Dictionary: This feature provides a global dictionary for in-memory databases, which can be used to store and access data in a consistent manner across multiple nodes.\n",
      "- Vectorized Query Processing: This feature enables you to perform multi-level joins and aggregations in a vectorized manner, which can significantly improve performance.\n",
      "- Machine Learning Enhancements: This feature includes a number of enhancements to support machine learning and data science activities, such as automated time series model search, explicit semantic analysis, and GLM link functions.\n",
      "- In Memory Advisor: This feature provides advice on how to optimize in-memory performance, including recommendations for memory sizes and other configuration settings.\n",
      "- Selective In Memory Columns: This feature allows you to select specific columns to be stored in memory, which can improve performance for those columns and reduce memory usage.\n",
      "- In Memory Sizing for Autonomous Databases: This feature automatically sizes the in-memory heap for autonomous databases, based on the size of the database and the available memory.\n",
      "- Pre Compiler Support for SQL BOOLEAN Data Type: This feature enables you to use the SQL BOOLEAN data type in PL/SQL functions and procedures, which can improve performance by reducing the number of bytes used to store a value.\n",
      "- UCP Asynchronous Extension: This feature allows you to use the UCP (User-Controlled Plane) asynchronous extension, which can improve performance by allowing you to execute UCP operations in parallel.\n",
      "- UCP Support for Self Driven Diagnosability: This feature enables you to use the UCP (User-Controlled Plane) self-driven diagnosability feature, which can automatically detect and diagnose issues with UCP operations.\n",
      "- Centralized Config Providers: This feature provides a central location for managing configuration settings, which can make it easier to maintain consistency across multiple environments.\n",
      "- Oracle SQL Access to Kafka: This feature enables you to access data in Kafka clusters using SQL queries, which can simplify data integration and analysis.\n",
      "- Text Indexes with Automatic Maintenance: This feature automatically maintains text indexes, which can improve performance by reducing the need for manual maintenance.\n",
      "- Transportable Binary XML: This feature allows you to transport binary XML data between different databases, which can simplify data exchange and integration.\n",
      "- GLM Link Functions: This feature includes a number of GLM (Generalized Linear Model) link functions, which can be used to perform advanced analysis and modeling of data.\n",
      "- Automated Data Clustering: This feature automatically clusters data based on similar values, which can improve performance by reducing the need for manual data grouping.\n",
      "- Extended Support and Faster Performance for JSON Materialized Views: This feature extends support for JSON (JavaScript Object Notation) materialized views and provides faster performance for their creation and maintenance.\n",
      "- Simplified Database Migration Across Platforms Using RMAN: This feature simplifies the process of migrating databases across platforms using the RMAN (Recovery Manager) tool, which can reduce the complexity and time required for such operations.\n",
      "- Blockchain Table User Chains: This feature allows you to create and manage user chains for blockchain tables, which can be used to maintain the integrity and security of the data in those tables.\n",
      "- Blockchain Table Row Versions: This feature allows you to manage row versions for blockchain tables, which can be used to maintain the history and integrity of the data in those tables.\n",
      "- RMAN Backup Encryption Algorithm Now Defaults to AES256: This feature changes the default encryption algorithm for RMAN backups to AES256, which is a stronger and more secure algorithm.\n",
      "- RMAN Operational Diagnostics and Upgrade Enhancements: This feature includes a number of enhancements to improve the operational diagnostics and upgrade process for RMAN, which can help you to identify and resolve issues more easily.\n",
      "- Simplified PL/SQL Package Upgrade: This feature simplifies the upgrade process for PL/SQL packages, which can reduce the time and effort required to maintain and upgrade those packages.\n",
      "- Estimate the Space Saved with Deduplication: This feature allows you to estimate the space saved by deduplicating data, which can help you to manage your storage more efficiently.\n",
      "- Pre Deployment Diagnostic for Oracle Globally Distributed Database: This feature provides a pre-deployment diagnostic for the Oracle Globally Distributed Database, which can help you to identify and resolve issues before you deploy the database.\n",
      "- RMAN SBT Library: This feature includes the RMAN SBT (Single-Byte Character) library, which can be used to support character data in RMAN scripts and commands.\n",
      "- Improved Performance of LOB (Large Object) Writes: This feature includes a number of improvements to the performance of LOB writes, which can reduce the time and resources required to write large objects to the database.\n",
      "- GLM (Generalized Linear Model) Link Functions: This feature includes a number of GLM (Generalized Linear Model) link functions, which can be used to perform advanced analysis and modeling of data using the GLM algorithm.\n",
      "- Explicit Semantic Analysis Support for Dense Projection with Embeddings: This feature includes support for explicit semantic analysis using dense projection with embeddings, which can be used to perform advanced analysis and modeling of data using semantic analysis techniques.\n",
      "- Automated Time Series Model Search: This feature includes a number of automated time series model search algorithms, which can be used to automatically select the best time series forecasting model and related hyperparameters for a given set of data.\n",
      "- Automated In Memory Sizing: This feature includes a number of automated in-memory sizing algorithms, which can be used to automatically determine the optimal size for an in-memory heap based on the available memory and the required performance.\n",
      "- In Memory RAC Level Global Dictionary: This feature includes a global dictionary for in-memory databases that is shared across multiple nodes in a RAC (Real Application Clusters) environment, which can be used to ensure consistency and coherence of data across those nodes.\n",
      "- Machine Learning Enhancements: This feature includes a number of enhancements to support machine learning and data science activities, such as the ability to create and manage machine learning models, to train and evaluate those models, and to use them to predict and analyze data.\n",
      "- Vectorized Query Processing: This feature includes support for vectorized query processing, which can be used to perform advanced analysis and aggregation of data in a more efficient and scalable manner.\n",
      "- Pre Compiler Support for SQL BOOLEAN Data Type: This feature includes support for the SQL BOOLEAN data type in PL/SQL functions and procedures, which can improve performance by reducing the number of bytes used to store a value and by allowing for more efficient processing of boolean expressions.\n",
      "\n",
      "\n",
      "CPU times: user 60.7 ms, sys: 10.5 ms, total: 71.2 ms\n",
      "Wall time: 48.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# the question\n",
    "get_answer(rag_chain, question=QUESTION6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93ffe1-3036-4251-9514-0c3cc240f224",
   "metadata": {},
   "source": [
    "#### Explore the vectore store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e055f1c4-27d9-465a-b0b4-278ad06bc67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve relevant splits for any question using similarity search.\n",
    "\n",
    "# This is simply \"top K\" retrieval where we select documents based on embedding similarity to the query.\n",
    "\n",
    "TOP_K = 10\n",
    "\n",
    "docs = vectorstore.similarity_search(QUESTION5, k=TOP_K)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2940dfc1-cc62-4778-a89d-81da8a466980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk n. 1\n",
      "2 Application Development JSON JSON Relational Duality JSON Relational Duality Views are fully updatable JSON views over relational data. Data is still stored in relational tables in a highly efficient normalized format but can be accessed by applications in the form of JSON documents. Duality views provide you with game changing flexibility and simplicity by overcoming the historical challenges developers have faced when building applications using relational or document models. Related Resources\n",
      "\n",
      "chunk n. 2\n",
      "developer productivity. Note For information about desupported features see Oracle Database Changes Desupports and Deprecations. JSON Relational Duality Data can be transparently accessed and updated as either JSON documents or relational tables. Developers benefit from the strengths of both which are simpler and more powerful than Object Relational Mapping ORM . See JSON Relational Duality . Operational Property Graphs in SQL\n",
      "\n",
      "chunk n. 3\n",
      "Contents 1 Introduction 2 Application Development JSON 2 1 JSON Relational Duality 2 1 JSON Schema 2 1 XML and JSON Search Index Enhancements 2 1 Changes for JSON Search Index and Data Guide 2 2 DBMS AQ Support for JSON Arrays 2 2 Enhancement to JSON TRANSFORM 2 2 JSON Type Support for External Tables 2 3 JSON JSON VALUE will Convert PL SQL Aggregate Type to from JSON 2 3 JSON ARRAY Constructor by Query 2 3 JSON EXPRESSION CHECK Parameter 2 3 New JSON Data Dictionary Views 2 4\n",
      "\n",
      "chunk n. 4\n",
      "values are on and off. The default is off. For now this parameter is limited to JSON relational duality views. An error is raised if a JSON path expression on a duality view does not match to an underlying column for example if the path expression has a typo. The error is raised during query compilations. This simplifies working with JSON relational duality views as incorrect JSON path expressions do not need to be debugged at runtime but instead are flagged at query\n",
      "\n",
      "chunk n. 5\n",
      "New JSON Data Dictionary Views 2 4 ORDERED in JSON SERIALIZE 2 4 Precheckable Constraints using JSON SCHEMA 2 4 Predicates for JSON VALUE and JSON QUERY 2 4 Tools to Migrate JSON Text Storage to JSON Type Storages 2 5 SQL 2 5 Application Usage Annotations 2 5 Direct Joins for UPDATE and DELETE Statements 2 5 IF NOT EXISTS Syntax Support 2 5 New Database Role for Application Developers 2 6 Aggregation over INTERVAL Data Types 2 6 Application Usage Domains 2 6 Automatic PL SQL to SQL Transpiler 2 6\n",
      "\n",
      "chunk n. 6\n",
      "New JSON Data Dictionary Views New dictionary views JSON INDEXES and TABLE VIRTUAL COLUMNS have been added. These new views provide better insight into the database objects that have been created to work with JSON data. Related Resources View Documentation ORDERED in JSON SERIALIZE The SQL function JSON SERIALIZE has an optional keyword ORDERED which reorders the key value pairs alphabetically ascending only . It can be combined with optional keywords PRETTY and ASCII .\n",
      "\n",
      "chunk n. 7\n",
      "JSON schema exists for a given PRECHECK column check constraint then an error is raised. Early detection of invalid data makes applications more resilient and reduces potential system downtime. All applications have access to the same information about whether data for a given column is precheckable and if so what JSON schema validates it. Related Resources View Documentation Predicates for JSON VALUE and JSON QUERY JSON path expressions with predicates can be used in JSON VALUE and JSON QUERY .\n",
      "\n",
      "chunk n. 8\n",
      "Support for JavaScript Object Notation JSON is an integral part of Oracle database. Oracle supports JSON natively with relational database features including transactions indexing declarative querying and views. A rich set of SQL functions is available to manipulate JSON in a relational model. Oracle Multilingual Engine MLE fully supports JSON both dynamic MLE as well as MLE Module Calls support interactions with the JSON data type.Chapter 2 JavaScript 2 19\n",
      "\n",
      "chunk n. 9\n",
      "document models. Related Resources View Documentation JSON Schema JSON Schema based validation is allowed with the SQL condition IS JSON and with a PL SQL utility function. A JSON schema is a JSON document that specifies allowed properties field names and the corresponding allowed data types and whether they are optional or mandatory. By default JSON data is schemaless providing flexibility. However you may want to ensure\n",
      "\n",
      "chunk n. 10\n",
      "keywords PRETTY and ASCII . Ordering the result of serialization makes it easier for both tools and humans to compare values. Related Resources View Documentation Precheckable Constraints using JSON SCHEMA To avoid sending invalid data to the database an application can often precheck validate it. PL SQL function DBMS JSON SCHEMA.describe provides JSON schemas that apps can use to perform validation equivalent to that performed by database\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    print(f\"chunk n. {i+1}\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452bd3e-2721-4cc8-892e-4f520b76b7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228be3c9-9c7b-4501-a2fe-656cdefd0a66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
